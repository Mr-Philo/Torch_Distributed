{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch数据并行\n",
    "\n",
    "Pytorch有两种方法可以在多个GPU上切分模型和数据：`nn.DataParallel`和`nn.distributedataparallel`。`DataParallel`更易于使用（只需简单包装单GPU模型），但效率不高。目前主流的分布式训练代码都采用`nn.distributedataparallel`方法，简称DDP。\n",
    "\n",
    "`DistributedDataParallel`通过多进程在多个GPUs间复制模型，在训练过程中，每个进程从磁盘加载batch数据，并将它们传递到其GPU。每一个GPU都有自己的前向过程，然后梯度在各个GPUs间进行All-Reduce。每一层的梯度不依赖于前一层，所以梯度的All-Reduce和后向过程同时计算，以进一步缓解网络瓶颈。在后向过程的最后，每个节点都得到了平均梯度，这样模型参数保持同步。\n",
    "\n",
    "以上所述的过程便是典型的**数据并行**过程，也是最简单的分布式训练方法。我们便利用这个方法，来探索分布式训练最简单的打开方式。\n",
    "\n",
    "首先，我们像上一节的示例那样，定义一个简单的神经网络来训练cifar数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 这部分代码定义在utils.py里面\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "# 网络结构（LeNet）\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU())\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(84, num_classes),\n",
    "            nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.fc(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "\n",
    "# 数据集加载（Cifar）\n",
    "def get_dataset(path='./data'):\n",
    "    DOWNLOAD = False\n",
    "    if not(os.path.exists(path)) or not os.listdir(path):\n",
    "    # not cifar dir or cifar is empyt dir\n",
    "        DOWNLOAD = True\n",
    "    else:\n",
    "        print(\"Cifar dataset already exist in '{}', skip download\".format(path))\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root = path,\n",
    "        train = True,\n",
    "        transform = transform,\n",
    "        download = DOWNLOAD\n",
    "    )\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root = path,\n",
    "        train = False,\n",
    "        transform = transform,\n",
    "        download = DOWNLOAD\n",
    "    )\n",
    "    \n",
    "    return trainset, testset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来是训练部分的代码。我们主要对这部分进行修改，以适配分布式训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cifar dataset already exist in './data', skip download\n",
      "Epoch: 0, Loss: 2.12, acc: 0.32, time cost: 33.72s\n",
      "Epoch: 1, Loss: 2.03, acc: 0.43, time cost: 33.75s\n",
      "Epoch: 2, Loss: 2.00, acc: 0.46, time cost: 33.04s\n",
      "Epoch: 3, Loss: 1.97, acc: 0.49, time cost: 23.91s\n",
      "Epoch: 4, Loss: 1.94, acc: 0.52, time cost: 20.76s\n",
      "Epoch: 5, Loss: 1.92, acc: 0.54, time cost: 41.05s\n",
      "Epoch: 6, Loss: 1.90, acc: 0.55, time cost: 20.00s\n",
      "Epoch: 7, Loss: 1.89, acc: 0.57, time cost: 24.13s\n",
      "Epoch: 8, Loss: 1.88, acc: 0.58, time cost: 32.31s\n",
      "Epoch: 9, Loss: 1.86, acc: 0.60, time cost: 33.40s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 模型\n",
    "net = ConvNet().to(device)\n",
    "\n",
    "# 数据集\n",
    "trainset, testset = get_dataset()\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练10个epoch\n",
    "for epoch in range(10):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    loss_sum,acc_sum = 0,0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criteria(outputs, labels)\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        predict = torch.argmax(outputs, dim=1)\n",
    "        acc_sum += torch.sum(predict == labels).item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Epoch: {}, Loss: {:.2f}, acc: {:.2f}, time cost: {:.2f}s\".format(epoch, loss_sum/len(train_loader), acc_sum/len(trainset), time.time()-t0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们利用分布式DDP对这段训练主函数进行修改。**注意**，由于DDP启动有专门的方法，所以接下来这部分只是代码示例，并不能在JupyterNotebook中直接运行。在后续我们会通过JupyterNotebook操控命令行来启动分布式代码，代码的所有内容都包含在`main.py`里。\n",
    "\n",
    "启动分布式训练离不开命令行参数`argparse`。因此我们先初始化一个`args`实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Distributed training')\n",
    "    \n",
    "    #! 如果使用torch.distributed.launch，请添加'local_rank'这一项\n",
    "    #! 由于torch.distributed.launch将会被弃用，改用torchrun，此时不需要添加'local_rank'这一项\n",
    "    # parser.add_argument('--local_rank', type=int, default=0)\n",
    "    \n",
    "    # world_size这一项指定了进程数\n",
    "    parser.add_argument('--world_size', type=int, default=1)\n",
    "    \n",
    "    # backend这一项指定了后端，可以是'nccl'或'gloo'，一般使用'nccl'\n",
    "    parser.add_argument('--backend', type=str, default='nccl')\n",
    "\n",
    "    # dist_url这一项指定了初始化进程组的地址，一般使用'env://'即可\n",
    "    parser.add_argument(\"--dist-url\", type=str, default=\"env://\")\n",
    "    \n",
    "    parser.add_argument(\"--sync-bn\", action=\"store_true\")\n",
    "    \n",
    "    return parser.parse_args()      # 在main.py内部调用args = get_args_parser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们定义一个初始化分布式环境的函数，该函数接收`args`，然后建立好分布式训练的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "def init_distributed_mode(args):\n",
    "    \n",
    "    # 利用os.environ来获取环境变量\n",
    "    if \"RANK\" in os.environ and \"WORLD_SIZE\" in os.environ:\n",
    "        args.rank = int(os.environ[\"RANK\"])\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "        args.gpu = int(os.environ[\"LOCAL_RANK\"])       \n",
    "    # slurm_procid调度方式来获取环境变量\n",
    "    elif \"SLURM_PROCID\" in os.environ:\n",
    "        args.rank = int(os.environ[\"SLURM_PROCID\"])\n",
    "        args.gpu = args.rank % torch.cuda.device_count()\n",
    "    elif hasattr(args, \"rank\"):\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Not using distributed mode\")\n",
    "        args.distributed = False\n",
    "        return\n",
    "\n",
    "    args.distributed = True\n",
    "\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    args.dist_backend = \"nccl\"\n",
    "    print(f\"| distributed init (rank {args.rank}): {args.dist_url}\", flush=True)\n",
    "    \n",
    "    # 使用torch.distributed.init_process_group来初始化进程组，这一步是初始化分布式训练的核心\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank\n",
    "    )\n",
    "    torch.distributed.barrier()\n",
    "    setup_for_distributed(args.rank == 0)\n",
    "\n",
    "\n",
    "def setup_for_distributed(is_master):\n",
    "    \"\"\"\n",
    "    This function disables printing when not in master process\n",
    "    该函数阻断了所有在非主进程中的打印操作，非常好用\n",
    "    \"\"\"\n",
    "    import builtins as __builtin__\n",
    "\n",
    "    builtin_print = __builtin__.print\n",
    "\n",
    "    def print(*args, **kwargs):\n",
    "        force = kwargs.pop(\"force\", False)\n",
    "        if is_master or force:\n",
    "            builtin_print(*args, **kwargs)\n",
    "\n",
    "    __builtin__.print = print"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化分布式环境后，针对训练主函数有两个非常重要的改变之处：\n",
    "\n",
    "1. **模型**： 模型需要使用`nn.parallel.DistributedDataParallel`来包裹，使得模型适配多卡环境；\n",
    "\n",
    "2. **数据集**：数据集（data_loader）需要先使用`torch.utils.data.distributed.DistributedSampler`定义采样器（这样每张卡上才能采得不一样的数据），然后在创建data_loader时**添加采样器，并将`shuffle`选项设置为`False`**\n",
    "\n",
    "除此之外，还有两个不会报错，但在训练过程中会有很大作用的改变：\n",
    "\n",
    "3. **Batch Norm同步**：可选项，这样能够使得模型在处理多张卡上面的数据时有更好的同步性能。因为如果每张卡单独在他们所负责的mini-batch上面做batch norm，很有可能会得到不如对整个batch做batch norm的效果\n",
    "\n",
    "4. **数据间的all-reduce**：比如分类任务的准确率acc就不能像上面的`acc_sum/len(trainset)`，因为每张卡上面只处理了一部分的mini-batch，算出来的acc_sum只是这张卡上面的数值，还需要在多张卡之间通信，收集所有卡所算出的数值，再做最终的acc计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = get_args_parser()\n",
    "    init_distributed_mode(args)\n",
    "    \n",
    "    # 接下来的主函数部分就是普通的训练代码，但需要作出相应的调整：\n",
    "    # 设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 模型\n",
    "    net = ConvNet().to(device)\n",
    "    #! ---------------------------------------------------------------\n",
    "    if args.distributed:\n",
    "        if args.sync_bn:\n",
    "            net = torch.nn.SyncBatchNorm.convert_sync_batchnorm(net)\n",
    "        net = torch.nn.parallel.DistributedDataParallel(net, device_ids=[args.gpu], output_device=args.gpu)\n",
    "    #! ----------------------------------------------------------------\n",
    "\n",
    "    # 数据集\n",
    "    trainset, testset = get_dataset()\n",
    "    #! ---------------------------------------------------------------\n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(trainset, num_replicas=args.world_size, rank=args.rank)\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, sampler=train_sampler)\n",
    "    #! ----------------------------------------------------------------\n",
    "    else:\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # 损失函数和优化器\n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    # 训练10个epoch\n",
    "    for epoch in range(10):\n",
    "        #! ---------------------------------------------------------------\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        #! ----------------------------------------------------------------\n",
    "        t0 = time.time()\n",
    "        \n",
    "        loss_sum,acc_sum = 0,0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criteria(outputs, labels)\n",
    "            \n",
    "            loss_sum += loss.item()\n",
    "            predict = torch.argmax(outputs, dim=1)\n",
    "            acc_sum += torch.sum(predict == labels).item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(\"Epoch: {}, Loss: {:.2f}, acc: {:.2f}, time cost: {:.2f}s\".format(epoch, loss_sum/len(train_loader), acc_sum/len(trainset), time.time()-t0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有这些设置已经写入main.py了，其中部分函数写入了`utils.py`。接下来就是启动该分布式脚本，观察运行情况。启动分布式脚本的方法主要有以下两种：\n",
    "\n",
    "1. `torch.multiprocessing.spawn`: 该方法需要在代码中加入`mp.spawn`程序段启动分布式训练，而不是从程序外部启动。\n",
    "\n",
    "2. `torch.distributed.launch`: 该方法是在命令行启动分布式训练代码。这种方法的优势在于，对于单机多卡、多机多卡，以及不同卡的数量、不同端口的值这些设置，能够更加方便地处理。目前这种方法也是更常用的方法。\n",
    "\n",
    "**注**：在新版pytorch中，`python -m torch.distributed.launch`的方法将被弃用，而转为`torchrun`方法。先前使用`torch.distributed.launch`必须在命令行参数argparse中隐式地定义`local_rank`选项，但`torchrun`则不需要。我们这部分的代码便更多地采用`torchrun`的方法。\n",
    "\n",
    "一个利用`torchrun`的最简单的例子如下：利用`--nproc_per_node=8`来指定使用8张卡来进行分布式训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "| distributed init (rank 4): env://\n",
      "| distributed init (rank 1): env://\n",
      "| distributed init (rank 2): env://\n",
      "| distributed init (rank 0): env://\n",
      "| distributed init (rank 5): env://\n",
      "| distributed init (rank 3): env://\n",
      "| distributed init (rank 7): env://\n",
      "| distributed init (rank 6): env://\n",
      "Cifar dataset already exist in './data', skip download\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "Epoch: 0, Loss: 2.20, acc: 0.03, time cost: 7.88s\n",
      "Epoch: 1, Loss: 2.11, acc: 0.04, time cost: 6.71s\n",
      "Epoch: 2, Loss: 2.05, acc: 0.05, time cost: 7.13s\n",
      "Epoch: 3, Loss: 2.02, acc: 0.05, time cost: 6.65s\n",
      "Epoch: 4, Loss: 1.99, acc: 0.06, time cost: 7.14s\n",
      "Epoch: 5, Loss: 1.98, acc: 0.06, time cost: 6.93s\n",
      "Epoch: 6, Loss: 1.96, acc: 0.06, time cost: 7.20s\n",
      "Epoch: 7, Loss: 1.94, acc: 0.06, time cost: 6.73s\n",
      "Epoch: 8, Loss: 1.94, acc: 0.07, time cost: 7.16s\n",
      "Epoch: 9, Loss: 1.93, acc: 0.07, time cost: 6.57s\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=8 main.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 不修改argparse的情况下，像下面这样运行代码会报错，无法识别`--local_rank`变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated\n",
      "and will be removed in future. Use torchrun.\n",
      "Note that --use_env is set by default in torchrun.\n",
      "If your script expects `--local_rank` argument to be set, please\n",
      "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
      "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
      "further instructions\n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=6\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=4\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=2\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=5\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=0\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=1\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=7\n",
      "usage: Distributed training [-h] [--world_size WORLD_SIZE] [--backend BACKEND]\n",
      "                            [--dist-url DIST_URL] [--sync-bn]\n",
      "Distributed training: error: unrecognized arguments: --local_rank=3\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 1368) of binary: /opt/conda/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 195, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 191, in main\n",
      "    launch(args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py\", line 176, in launch\n",
      "    run(args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py\", line 753, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 132, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 246, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "main.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 2 (pid: 1369)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 2 (pid: 1370)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 2 (pid: 1371)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[4]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 4 (local_rank: 4)\n",
      "  exitcode  : 2 (pid: 1372)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[5]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 5 (local_rank: 5)\n",
      "  exitcode  : 2 (pid: 1373)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[6]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 6 (local_rank: 6)\n",
      "  exitcode  : 2 (pid: 1374)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[7]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 7 (local_rank: 7)\n",
      "  exitcode  : 2 (pid: 1375)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-04-19_07:39:39\n",
      "  host      : GCR-OPENPAI-12.redmond.corp.microsoft.com\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 2 (pid: 1368)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node=8 main.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上便是pytorch数据并行和启动分布式训练的一些基本代码方案了。接下来一节将会介绍一些涉及到分布式的api方法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
