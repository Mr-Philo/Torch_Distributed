{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSpeed 加速框架\n",
    "\n",
    "DeepSpeed是微软开源的一款针对大规模模型分布式训练的工具，官方地址:\n",
    "\n",
    "开源库：https://github.com/microsoft/DeepSpeed\n",
    "\n",
    "官方示例：https://github.com/microsoft/DeepSpeedExamples\n",
    "\n",
    "官方文档：https://www.deepspeed.ai/getting-started/\n",
    "\n",
    "接下来我们依据教程和示例，将DeepSpeed应用在cifar10模型训练的代码上"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先需要更改argparse设置部分。根据DeepSpeed官方文档的指引，我们需要添加DeepSpeed训练的config设置文件，并将其置入argparse中，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import utils\n",
    "import deepspeed\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Distributed training')\n",
    "    # parser.add_argument('--local_rank', type=int, default=0)\n",
    "    parser.add_argument('--world_size', type=int, default=1)\n",
    "    parser.add_argument('--backend', type=str, default='nccl')\n",
    "    parser.add_argument(\"--dist-url\", type=str, default=\"env://\")\n",
    "    parser.add_argument(\"--sync-bn\", action=\"store_true\")\n",
    "    parser.add_argument(\"--use-deepspeed\", action=\"store_true\")\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    #! ---------------------------------------------------------------\n",
    "    if args.use_deepspeed:\n",
    "        parser = deepspeed.add_config_arguments(parser)\n",
    "    #! ---------------------------------------------------------------\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_args_parser()\n",
    "    #! ---------------------------------------------------------------\n",
    "    if args.use_deepspeed:\n",
    "        args.deepspeed_config = \"./config/deepspeed_cifar_config.json\"\n",
    "    #! ---------------------------------------------------------------\n",
    "    utils.init_distributed_mode(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，config文件我们使用了[最简单的版本](./config/deepspeed_cifar_config.json)，如下。在实际代码运行中，应根据代码执行的具体情况调整config文件的设置。\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"train_batch_size\": 64,\n",
    "  \"gradient_accumulation_steps\": 1,\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"Adam\",\n",
    "    \"params\": {\n",
    "      \"lr\": 0.001\n",
    "    }\n",
    "  },\n",
    "  \"fp16\": {\n",
    "    \"enabled\": false\n",
    "  },\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": 2\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其次，我们需要更新分布式环境的初始化方式。根据官方文档（https://www.deepspeed.ai/getting-started/#writing-deepspeed-models），使用deepspeed初始化需要代替掉之前我们所使用的`torch.distributed.init_process_group(...)`方法，改用`deepspeed.init_distributed()`方法，即："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def init_distributed_mode(args):\n",
    "    '''...'''\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    args.dist_backend = \"nccl\"\n",
    "    print(f\"| distributed init (rank {args.rank}): {args.dist_url}\", flush=True)\n",
    "\n",
    "    if args.use_deepspeed:\n",
    "        import deepspeed\n",
    "        deepspeed.init_distributed(dist_backend=args.dist_backend, init_method=args.dist_url)\n",
    "    else:\n",
    "        torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们使用DeepSpeed框架对模型进行封装："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    # modify here\n",
    "    if args.use_deepspeed:\n",
    "        net, optimizer, _, _ = deepspeed.initialize(args=args, model=net, optimizer=optimizer)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        # start training\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码的核心是`deepspeed.initialize()`这个函数。\n",
    "\n",
    "接下来，模型的前向过程也需要做一定的调整。具体来说，利用`deepspeed.initialize()`函数封装过的模型，会自动地执行优化器清零（即`optimizer.zero_grad()`）和学习率规划的步骤（ learning rate scheduler），因此前向过程会略简单一些："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    loss = criteria(outputs, labels)\n",
    "    \n",
    "    loss_sum += loss.item()\n",
    "    predict = torch.argmax(outputs, dim=1)\n",
    "    acc_sum += torch.sum(predict == labels).item()\n",
    "    \n",
    "    if args.use_deepspeed:\n",
    "        net.backward(loss)\n",
    "        net.step()\n",
    "    else:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在一个非常简单的带有deepspeed训练框架的cifar代码就搭建完成了。接下来我们在多卡上试一试启动deepspeed训练的效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "| distributed init (rank 0): env://\n",
      "[2023-04-20 07:35:29,185] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "| distributed init (rank 6): env://\n",
      "| distributed init (rank 2): env://\n",
      "| distributed init (rank 1): env://\n",
      "| distributed init (rank 7): env://\n",
      "| distributed init (rank 3): env://\n",
      "| distributed init (rank 5): env://\n",
      "| distributed init (rank 4): env://\n",
      "Cifar dataset already exist in './data', skip download\n",
      "[2023-04-20 07:35:44,801] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.8.3+4d27225f, git-hash=4d27225f, git-branch=master\n",
      "[2023-04-20 07:35:45,020] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-04-20 07:35:45,021] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-04-20 07:35:45,022] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-04-20 07:35:45,022] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2023-04-20 07:35:45,022] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2023-04-20 07:35:45,022] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float32 ZeRO stage 2 optimizer\n",
      "[2023-04-20 07:35:45,023] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 500,000,000\n",
      "[2023-04-20 07:35:45,023] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 500,000,000\n",
      "[2023-04-20 07:35:45,023] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: False\n",
      "[2023-04-20 07:35:45,023] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.20662808418273926 seconds\n",
      "Rank: 0 partition count [8] and sizes[(7752, False)] \n",
      "ninja: no work to do.\n",
      "ninja: no work to do.\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "[2023-04-20 07:35:52,233] [INFO] [utils.py:780:see_memory_usage] Before initializing optimizer states\n",
      "[2023-04-20 07:35:52,234] [INFO] [utils.py:781:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB \n",
      "[2023-04-20 07:35:52,234] [INFO] [utils.py:788:see_memory_usage] CPU Virtual Memory:  used = 19.48 GB, percent = 3.9%\n",
      "[2023-04-20 07:35:52,341] [INFO] [utils.py:780:see_memory_usage] After initializing optimizer states\n",
      "[2023-04-20 07:35:52,342] [INFO] [utils.py:781:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB \n",
      "[2023-04-20 07:35:52,342] [INFO] [utils.py:788:see_memory_usage] CPU Virtual Memory:  used = 19.49 GB, percent = 3.9%\n",
      "[2023-04-20 07:35:52,342] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-04-20 07:35:52,414] [INFO] [utils.py:780:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-04-20 07:35:52,415] [INFO] [utils.py:781:see_memory_usage] MA 0.0 GB         Max_MA 0.0 GB         CA 0.0 GB         Max_CA 0 GB \n",
      "[2023-04-20 07:35:52,415] [INFO] [utils.py:788:see_memory_usage] CPU Virtual Memory:  used = 19.52 GB, percent = 3.9%\n",
      "[2023-04-20 07:35:52,415] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2023-04-20 07:35:52,415] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-04-20 07:35:52,416] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-04-20 07:35:52,416] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:52,416] [INFO] [config.py:935:print] DeepSpeedEngine configuration:\n",
      "[2023-04-20 07:35:52,416] [INFO] [config.py:939:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-04-20 07:35:52,416] [INFO] [config.py:939:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-04-20 07:35:52,416] [INFO] [config.py:939:print]   amp_enabled .................. False\n",
      "[2023-04-20 07:35:52,416] [INFO] [config.py:939:print]   amp_params ................... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   bfloat16_enabled ............. False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fe9d043dfd0>\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   communication_data_type ...... None\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   curriculum_enabled_legacy .... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   curriculum_params_legacy ..... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   data_efficiency_enabled ...... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   dataloader_drop_last ......... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   disable_allgather ............ False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   dump_state ................... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_enabled ........... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   eigenvalue_verbose ........... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   elasticity_enabled ........... False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   fp16_auto_cast ............... None\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   fp16_enabled ................. False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   global_rank .................. 0\n",
      "[2023-04-20 07:35:52,417] [INFO] [config.py:939:print]   grad_accum_dtype ............. None\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   gradient_accumulation_steps .. 1\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   gradient_clipping ............ 0.0\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   load_universal_checkpoint .... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   loss_scale ................... 0\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   memory_breakdown ............. False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   optimizer_name ............... adam\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   optimizer_params ............. {'lr': 0.001}\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   pld_enabled .................. False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   pld_params ................... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   prescale_gradients ........... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   scheduler_name ............... None\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   scheduler_params ............. None\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   sparse_attention ............. None\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   sparse_gradients_enabled ..... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   steps_per_print .............. 10\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   train_batch_size ............. 64\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   train_micro_batch_size_per_gpu  8\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   use_node_local_storage ....... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   wall_clock_breakdown ......... False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   world_size ................... 8\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   zero_allow_untested_optimizer  False\n",
      "[2023-04-20 07:35:52,418] [INFO] [config.py:939:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
      "[2023-04-20 07:35:52,419] [INFO] [config.py:939:print]   zero_enabled ................. True\n",
      "[2023-04-20 07:35:52,419] [INFO] [config.py:939:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-04-20 07:35:52,419] [INFO] [config.py:939:print]   zero_optimization_stage ...... 2\n",
      "[2023-04-20 07:35:52,419] [INFO] [config.py:925:print_user_config]   json = {\n",
      "    \"train_batch_size\": 64, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\", \n",
      "        \"params\": {\n",
      "            \"lr\": 0.001\n",
      "        }\n",
      "    }, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2\n",
      "    }\n",
      "}\n",
      "Using /root/.cache/torch_extensions/py38_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0008640289306640625 seconds\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead\n",
      "  warnings.warn(\"is_namedtuple is deprecated, please use the python checks instead\")\n",
      "[2023-04-20 07:35:53,134] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:53,135] [INFO] [timer.py:199:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=4380.8673428587745, CurrSamplesPerSec=4987.837823776432, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:53,426] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:53,427] [INFO] [timer.py:199:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=4537.256809634481, CurrSamplesPerSec=4650.6489258489255, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:53,704] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:53,704] [INFO] [timer.py:199:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=4732.814874611328, CurrSamplesPerSec=5746.975015521634, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:53,991] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:53,991] [INFO] [timer.py:199:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=4751.138618210138, CurrSamplesPerSec=5048.056566872273, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:54,274] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:54,275] [INFO] [timer.py:199:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=4795.43843257752, CurrSamplesPerSec=4881.620978741203, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:54,594] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:54,594] [INFO] [timer.py:199:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=4747.151481002102, CurrSamplesPerSec=5289.368591133005, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:54,879] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:54,880] [INFO] [timer.py:199:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=4831.94280535014, CurrSamplesPerSec=5725.523760771265, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:55,177] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:55,177] [INFO] [timer.py:199:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=4848.428036918323, CurrSamplesPerSec=5546.5309006756615, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:55,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:55,460] [INFO] [timer.py:199:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=4887.506349927223, CurrSamplesPerSec=4894.170361726954, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 0, Loss: 2.20, acc: 0.25, time cost: 3.30s\n",
      "[2023-04-20 07:35:55,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:55,781] [INFO] [timer.py:199:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=4870.906456405524, CurrSamplesPerSec=5672.050374001606, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:56,049] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:56,049] [INFO] [timer.py:199:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=4937.294708562641, CurrSamplesPerSec=5621.331769731744, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:56,316] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:56,316] [INFO] [timer.py:199:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=5000.464727062393, CurrSamplesPerSec=5751.1613497589715, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:56,584] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:56,584] [INFO] [timer.py:199:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=5053.839891191587, CurrSamplesPerSec=5681.414155096512, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:56,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:56,860] [INFO] [timer.py:199:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=5074.511728511838, CurrSamplesPerSec=4361.045862914886, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:57,156] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:57,157] [INFO] [timer.py:199:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=5071.7266282308465, CurrSamplesPerSec=5155.874615857406, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:57,466] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:57,466] [INFO] [timer.py:199:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=5035.320546609017, CurrSamplesPerSec=4023.9766148495705, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:57,780] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:57,780] [INFO] [timer.py:199:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=4998.768696601388, CurrSamplesPerSec=4964.591381542445, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:58,072] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:58,073] [INFO] [timer.py:199:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=5015.327983259537, CurrSamplesPerSec=4450.337478033091, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:58,365] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:58,366] [INFO] [timer.py:199:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=4998.19851317411, CurrSamplesPerSec=5064.151074386402, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 1, Loss: 2.11, acc: 0.34, time cost: 2.82s\n",
      "[2023-04-20 07:35:58,658] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:58,659] [INFO] [timer.py:199:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=4981.607987785504, CurrSamplesPerSec=4501.5336731955995, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:58,946] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:58,947] [INFO] [timer.py:199:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=4981.438666500602, CurrSamplesPerSec=4770.320159226613, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:59,240] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:59,241] [INFO] [timer.py:199:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=4976.836654545256, CurrSamplesPerSec=4726.808522627223, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:59,530] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:59,530] [INFO] [timer.py:199:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=4970.702365440074, CurrSamplesPerSec=5136.734203375559, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:35:59,820] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:35:59,820] [INFO] [timer.py:199:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=4963.941797359884, CurrSamplesPerSec=4502.968412930066, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:00,115] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:00,115] [INFO] [timer.py:199:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=4956.924601306021, CurrSamplesPerSec=4069.917156892474, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:00,406] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:00,407] [INFO] [timer.py:199:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=4950.474604999056, CurrSamplesPerSec=4791.693400689027, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:00,699] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:00,699] [INFO] [timer.py:199:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=4944.063505511608, CurrSamplesPerSec=4525.66773443032, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:00,991] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:00,991] [INFO] [timer.py:199:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=4937.2499507598595, CurrSamplesPerSec=4974.619743889105, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:01,279] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:01,279] [INFO] [timer.py:199:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=4933.820902788246, CurrSamplesPerSec=4795.802547656906, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 2, Loss: 2.07, acc: 0.39, time cost: 2.85s\n",
      "[2023-04-20 07:36:01,565] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:01,566] [INFO] [timer.py:199:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=4935.302756174206, CurrSamplesPerSec=4327.510172497179, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:01,853] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:01,854] [INFO] [timer.py:199:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=4935.031969682409, CurrSamplesPerSec=4143.289745014509, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:02,139] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:02,139] [INFO] [timer.py:199:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=4935.798605827658, CurrSamplesPerSec=4407.951919603271, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:02,422] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:02,422] [INFO] [timer.py:199:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=4939.267794528261, CurrSamplesPerSec=4812.137317820841, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:02,705] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:02,706] [INFO] [timer.py:199:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=4943.830208647835, CurrSamplesPerSec=4627.9581400962015, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:03,000] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:03,001] [INFO] [timer.py:199:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=4936.493574008136, CurrSamplesPerSec=5061.763765273797, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:03,282] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:03,283] [INFO] [timer.py:199:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=4942.096830029633, CurrSamplesPerSec=5081.887395403431, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:03,568] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:03,568] [INFO] [timer.py:199:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=4945.598146727054, CurrSamplesPerSec=4967.531292793959, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:03,856] [INFO] [logging.py:96:log_dist] [Rank 0] step=380, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:03,857] [INFO] [timer.py:199:stop] epoch=0/micro_step=380/global_step=380, RunningAvgSamplesPerSec=4944.165649128386, CurrSamplesPerSec=5126.629667118657, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:04,143] [INFO] [logging.py:96:log_dist] [Rank 0] step=390, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:04,144] [INFO] [timer.py:199:stop] epoch=0/micro_step=390/global_step=390, RunningAvgSamplesPerSec=4943.594871964528, CurrSamplesPerSec=5144.0183964433545, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 3, Loss: 2.05, acc: 0.42, time cost: 2.81s\n",
      "[2023-04-20 07:36:04,428] [INFO] [logging.py:96:log_dist] [Rank 0] step=400, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:04,428] [INFO] [timer.py:199:stop] epoch=0/micro_step=400/global_step=400, RunningAvgSamplesPerSec=4946.387774614419, CurrSamplesPerSec=4461.209818683419, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:04,709] [INFO] [logging.py:96:log_dist] [Rank 0] step=410, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:04,709] [INFO] [timer.py:199:stop] epoch=0/micro_step=410/global_step=410, RunningAvgSamplesPerSec=4950.745579350244, CurrSamplesPerSec=5071.134922733971, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:04,997] [INFO] [logging.py:96:log_dist] [Rank 0] step=420, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:04,997] [INFO] [timer.py:199:stop] epoch=0/micro_step=420/global_step=420, RunningAvgSamplesPerSec=4950.090178039278, CurrSamplesPerSec=4838.941774525003, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:05,287] [INFO] [logging.py:96:log_dist] [Rank 0] step=430, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:05,287] [INFO] [timer.py:199:stop] epoch=0/micro_step=430/global_step=430, RunningAvgSamplesPerSec=4946.623023434663, CurrSamplesPerSec=5049.101025110505, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:05,567] [INFO] [logging.py:96:log_dist] [Rank 0] step=440, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:05,568] [INFO] [timer.py:199:stop] epoch=0/micro_step=440/global_step=440, RunningAvgSamplesPerSec=4952.438775921964, CurrSamplesPerSec=5255.8142303324585, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:05,848] [INFO] [logging.py:96:log_dist] [Rank 0] step=450, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:05,849] [INFO] [timer.py:199:stop] epoch=0/micro_step=450/global_step=450, RunningAvgSamplesPerSec=4958.1378949208965, CurrSamplesPerSec=4140.7971369953875, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:06,133] [INFO] [logging.py:96:log_dist] [Rank 0] step=460, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:06,134] [INFO] [timer.py:199:stop] epoch=0/micro_step=460/global_step=460, RunningAvgSamplesPerSec=4958.88619319569, CurrSamplesPerSec=4871.786860254084, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:06,414] [INFO] [logging.py:96:log_dist] [Rank 0] step=470, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:06,415] [INFO] [timer.py:199:stop] epoch=0/micro_step=470/global_step=470, RunningAvgSamplesPerSec=4963.2464574665455, CurrSamplesPerSec=4787.079019170754, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:06,683] [INFO] [logging.py:96:log_dist] [Rank 0] step=480, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:06,683] [INFO] [timer.py:199:stop] epoch=0/micro_step=480/global_step=480, RunningAvgSamplesPerSec=4976.701814369376, CurrSamplesPerSec=5617.567353772104, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:06,956] [INFO] [logging.py:96:log_dist] [Rank 0] step=490, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:06,957] [INFO] [timer.py:199:stop] epoch=0/micro_step=490/global_step=490, RunningAvgSamplesPerSec=4980.977577093523, CurrSamplesPerSec=5430.288592640543, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 4, Loss: 2.01, acc: 0.44, time cost: 2.76s\n",
      "[2023-04-20 07:36:07,228] [INFO] [logging.py:96:log_dist] [Rank 0] step=500, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:07,229] [INFO] [timer.py:199:stop] epoch=0/micro_step=500/global_step=500, RunningAvgSamplesPerSec=4991.991023435993, CurrSamplesPerSec=5556.519478368868, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:07,493] [INFO] [logging.py:96:log_dist] [Rank 0] step=510, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:07,494] [INFO] [timer.py:199:stop] epoch=0/micro_step=510/global_step=510, RunningAvgSamplesPerSec=5004.469450470729, CurrSamplesPerSec=5705.686993857206, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:07,764] [INFO] [logging.py:96:log_dist] [Rank 0] step=520, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:07,765] [INFO] [timer.py:199:stop] epoch=0/micro_step=520/global_step=520, RunningAvgSamplesPerSec=5012.879633372594, CurrSamplesPerSec=4404.191238720263, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:08,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=530, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:08,046] [INFO] [timer.py:199:stop] epoch=0/micro_step=530/global_step=530, RunningAvgSamplesPerSec=5013.977078908682, CurrSamplesPerSec=5451.683746623611, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:08,319] [INFO] [logging.py:96:log_dist] [Rank 0] step=540, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:08,320] [INFO] [timer.py:199:stop] epoch=0/micro_step=540/global_step=540, RunningAvgSamplesPerSec=5020.994953495617, CurrSamplesPerSec=5287.805692898651, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:08,599] [INFO] [logging.py:96:log_dist] [Rank 0] step=550, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:08,599] [INFO] [timer.py:199:stop] epoch=0/micro_step=550/global_step=550, RunningAvgSamplesPerSec=5023.097465436773, CurrSamplesPerSec=4981.913366244757, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:08,870] [INFO] [logging.py:96:log_dist] [Rank 0] step=560, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:08,871] [INFO] [timer.py:199:stop] epoch=0/micro_step=560/global_step=560, RunningAvgSamplesPerSec=5029.757038200228, CurrSamplesPerSec=5753.750075020363, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:09,136] [INFO] [logging.py:96:log_dist] [Rank 0] step=570, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:09,136] [INFO] [timer.py:199:stop] epoch=0/micro_step=570/global_step=570, RunningAvgSamplesPerSec=5041.22426869744, CurrSamplesPerSec=5599.755011786303, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:09,427] [INFO] [logging.py:96:log_dist] [Rank 0] step=580, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:09,427] [INFO] [timer.py:199:stop] epoch=0/micro_step=580/global_step=580, RunningAvgSamplesPerSec=5043.629895733483, CurrSamplesPerSec=5458.334980377804, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 5, Loss: 2.00, acc: 0.46, time cost: 2.71s\n",
      "[2023-04-20 07:36:09,738] [INFO] [logging.py:96:log_dist] [Rank 0] step=590, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:09,739] [INFO] [timer.py:199:stop] epoch=0/micro_step=590/global_step=590, RunningAvgSamplesPerSec=5034.993035513246, CurrSamplesPerSec=3385.2759442587803, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:10,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=600, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:10,045] [INFO] [timer.py:199:stop] epoch=0/micro_step=600/global_step=600, RunningAvgSamplesPerSec=5022.401753149342, CurrSamplesPerSec=5067.305772643183, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:10,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=610, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:10,341] [INFO] [timer.py:199:stop] epoch=0/micro_step=610/global_step=610, RunningAvgSamplesPerSec=5027.304228364377, CurrSamplesPerSec=5267.261660420305, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:10,634] [INFO] [logging.py:96:log_dist] [Rank 0] step=620, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:10,636] [INFO] [timer.py:199:stop] epoch=0/micro_step=620/global_step=620, RunningAvgSamplesPerSec=5023.429314734912, CurrSamplesPerSec=4670.554616000279, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:10,940] [INFO] [logging.py:96:log_dist] [Rank 0] step=630, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:10,941] [INFO] [timer.py:199:stop] epoch=0/micro_step=630/global_step=630, RunningAvgSamplesPerSec=5029.256115002659, CurrSamplesPerSec=5202.842501066016, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:11,218] [INFO] [logging.py:96:log_dist] [Rank 0] step=640, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:11,219] [INFO] [timer.py:199:stop] epoch=0/micro_step=640/global_step=640, RunningAvgSamplesPerSec=5036.817281999242, CurrSamplesPerSec=5657.227734457323, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:11,505] [INFO] [logging.py:96:log_dist] [Rank 0] step=650, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:11,506] [INFO] [timer.py:199:stop] epoch=0/micro_step=650/global_step=650, RunningAvgSamplesPerSec=5037.175155161872, CurrSamplesPerSec=3169.4742956998134, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:11,805] [INFO] [logging.py:96:log_dist] [Rank 0] step=660, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:11,806] [INFO] [timer.py:199:stop] epoch=0/micro_step=660/global_step=660, RunningAvgSamplesPerSec=5028.091814508576, CurrSamplesPerSec=5383.3518369966305, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:12,087] [INFO] [logging.py:96:log_dist] [Rank 0] step=670, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:12,087] [INFO] [timer.py:199:stop] epoch=0/micro_step=670/global_step=670, RunningAvgSamplesPerSec=5032.413422254937, CurrSamplesPerSec=4275.947879830514, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:12,381] [INFO] [logging.py:96:log_dist] [Rank 0] step=680, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:12,381] [INFO] [timer.py:199:stop] epoch=0/micro_step=680/global_step=680, RunningAvgSamplesPerSec=5034.963657729375, CurrSamplesPerSec=5577.879605194805, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 6, Loss: 1.98, acc: 0.48, time cost: 2.89s\n",
      "[2023-04-20 07:36:12,679] [INFO] [logging.py:96:log_dist] [Rank 0] step=690, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:12,680] [INFO] [timer.py:199:stop] epoch=0/micro_step=690/global_step=690, RunningAvgSamplesPerSec=5029.707698402284, CurrSamplesPerSec=4883.308277242132, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:12,957] [INFO] [logging.py:96:log_dist] [Rank 0] step=700, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:12,957] [INFO] [timer.py:199:stop] epoch=0/micro_step=700/global_step=700, RunningAvgSamplesPerSec=5032.915587757877, CurrSamplesPerSec=5708.477713507996, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:13,241] [INFO] [logging.py:96:log_dist] [Rank 0] step=710, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:13,241] [INFO] [timer.py:199:stop] epoch=0/micro_step=710/global_step=710, RunningAvgSamplesPerSec=5034.8103136144155, CurrSamplesPerSec=5009.339130759326, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:13,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=720, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:13,519] [INFO] [timer.py:199:stop] epoch=0/micro_step=720/global_step=720, RunningAvgSamplesPerSec=5037.876933985991, CurrSamplesPerSec=5734.20750646188, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:13,793] [INFO] [logging.py:96:log_dist] [Rank 0] step=730, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:13,794] [INFO] [timer.py:199:stop] epoch=0/micro_step=730/global_step=730, RunningAvgSamplesPerSec=5042.138794123872, CurrSamplesPerSec=4319.085067014207, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:14,073] [INFO] [logging.py:96:log_dist] [Rank 0] step=740, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:14,074] [INFO] [timer.py:199:stop] epoch=0/micro_step=740/global_step=740, RunningAvgSamplesPerSec=5046.683140876751, CurrSamplesPerSec=5490.375848809621, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:14,364] [INFO] [logging.py:96:log_dist] [Rank 0] step=750, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:14,365] [INFO] [timer.py:199:stop] epoch=0/micro_step=750/global_step=750, RunningAvgSamplesPerSec=5051.683940712435, CurrSamplesPerSec=5646.042739357227, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:14,638] [INFO] [logging.py:96:log_dist] [Rank 0] step=760, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:14,639] [INFO] [timer.py:199:stop] epoch=0/micro_step=760/global_step=760, RunningAvgSamplesPerSec=5057.013363126872, CurrSamplesPerSec=5546.072519162827, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:14,913] [INFO] [logging.py:96:log_dist] [Rank 0] step=770, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:14,914] [INFO] [timer.py:199:stop] epoch=0/micro_step=770/global_step=770, RunningAvgSamplesPerSec=5062.166092908398, CurrSamplesPerSec=5365.275343779981, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:15,199] [INFO] [logging.py:96:log_dist] [Rank 0] step=780, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:15,200] [INFO] [timer.py:199:stop] epoch=0/micro_step=780/global_step=780, RunningAvgSamplesPerSec=5060.802113547337, CurrSamplesPerSec=5386.484518912411, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 7, Loss: 1.96, acc: 0.49, time cost: 2.75s\n",
      "[2023-04-20 07:36:15,479] [INFO] [logging.py:96:log_dist] [Rank 0] step=790, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:15,479] [INFO] [timer.py:199:stop] epoch=0/micro_step=790/global_step=790, RunningAvgSamplesPerSec=5063.25053993297, CurrSamplesPerSec=3976.703742111345, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:15,759] [INFO] [logging.py:96:log_dist] [Rank 0] step=800, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:15,759] [INFO] [timer.py:199:stop] epoch=0/micro_step=800/global_step=800, RunningAvgSamplesPerSec=5065.6293424858495, CurrSamplesPerSec=4387.777567099284, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:16,046] [INFO] [logging.py:96:log_dist] [Rank 0] step=810, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:16,047] [INFO] [timer.py:199:stop] epoch=0/micro_step=810/global_step=810, RunningAvgSamplesPerSec=5064.330568095209, CurrSamplesPerSec=4970.658766017332, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:16,344] [INFO] [logging.py:96:log_dist] [Rank 0] step=820, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:16,345] [INFO] [timer.py:199:stop] epoch=0/micro_step=820/global_step=820, RunningAvgSamplesPerSec=5057.75943049101, CurrSamplesPerSec=5342.211749721382, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:16,612] [INFO] [logging.py:96:log_dist] [Rank 0] step=830, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:16,612] [INFO] [timer.py:199:stop] epoch=0/micro_step=830/global_step=830, RunningAvgSamplesPerSec=5065.0748864830975, CurrSamplesPerSec=5685.746335677371, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:16,927] [INFO] [logging.py:96:log_dist] [Rank 0] step=840, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:16,928] [INFO] [timer.py:199:stop] epoch=0/micro_step=840/global_step=840, RunningAvgSamplesPerSec=5051.865859433214, CurrSamplesPerSec=4162.370811431052, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:17,220] [INFO] [logging.py:96:log_dist] [Rank 0] step=850, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:17,220] [INFO] [timer.py:199:stop] epoch=0/micro_step=850/global_step=850, RunningAvgSamplesPerSec=5046.011339408278, CurrSamplesPerSec=5079.387223735997, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:17,518] [INFO] [logging.py:96:log_dist] [Rank 0] step=860, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:17,519] [INFO] [timer.py:199:stop] epoch=0/micro_step=860/global_step=860, RunningAvgSamplesPerSec=5037.427789316899, CurrSamplesPerSec=4933.659063757834, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:17,788] [INFO] [logging.py:96:log_dist] [Rank 0] step=870, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:17,789] [INFO] [timer.py:199:stop] epoch=0/micro_step=870/global_step=870, RunningAvgSamplesPerSec=5043.096919384355, CurrSamplesPerSec=5735.187608161521, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:18,067] [INFO] [logging.py:96:log_dist] [Rank 0] step=880, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:18,068] [INFO] [timer.py:199:stop] epoch=0/micro_step=880/global_step=880, RunningAvgSamplesPerSec=5044.508552425457, CurrSamplesPerSec=5548.938647263106, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 8, Loss: 1.96, acc: 0.50, time cost: 2.81s\n",
      "[2023-04-20 07:36:18,340] [INFO] [logging.py:96:log_dist] [Rank 0] step=890, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:18,341] [INFO] [timer.py:199:stop] epoch=0/micro_step=890/global_step=890, RunningAvgSamplesPerSec=5049.168724508915, CurrSamplesPerSec=5667.140752000338, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:18,615] [INFO] [logging.py:96:log_dist] [Rank 0] step=900, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:18,616] [INFO] [timer.py:199:stop] epoch=0/micro_step=900/global_step=900, RunningAvgSamplesPerSec=5052.199510195253, CurrSamplesPerSec=5081.887395403431, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:18,911] [INFO] [logging.py:96:log_dist] [Rank 0] step=910, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:18,911] [INFO] [timer.py:199:stop] epoch=0/micro_step=910/global_step=910, RunningAvgSamplesPerSec=5045.611498375626, CurrSamplesPerSec=4694.404812703298, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:19,200] [INFO] [logging.py:96:log_dist] [Rank 0] step=920, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:19,200] [INFO] [timer.py:199:stop] epoch=0/micro_step=920/global_step=920, RunningAvgSamplesPerSec=5043.138595423155, CurrSamplesPerSec=5331.918879729864, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:19,497] [INFO] [logging.py:96:log_dist] [Rank 0] step=930, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:19,498] [INFO] [timer.py:199:stop] epoch=0/micro_step=930/global_step=930, RunningAvgSamplesPerSec=5042.109314474771, CurrSamplesPerSec=5138.897618500651, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:19,778] [INFO] [logging.py:96:log_dist] [Rank 0] step=940, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:19,778] [INFO] [timer.py:199:stop] epoch=0/micro_step=940/global_step=940, RunningAvgSamplesPerSec=5042.795100531472, CurrSamplesPerSec=5697.693969817248, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:20,074] [INFO] [logging.py:96:log_dist] [Rank 0] step=950, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:20,075] [INFO] [timer.py:199:stop] epoch=0/micro_step=950/global_step=950, RunningAvgSamplesPerSec=5037.909063533268, CurrSamplesPerSec=4971.763520521558, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:20,347] [INFO] [logging.py:96:log_dist] [Rank 0] step=960, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:20,348] [INFO] [timer.py:199:stop] epoch=0/micro_step=960/global_step=960, RunningAvgSamplesPerSec=5042.377006990669, CurrSamplesPerSec=5707.992174874543, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:20,639] [INFO] [logging.py:96:log_dist] [Rank 0] step=970, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:20,639] [INFO] [timer.py:199:stop] epoch=0/micro_step=970/global_step=970, RunningAvgSamplesPerSec=5039.610281936388, CurrSamplesPerSec=3882.3791038731883, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "[2023-04-20 07:36:20,923] [INFO] [logging.py:96:log_dist] [Rank 0] step=980, skipped=0, lr=[0.001], mom=[(0.9, 0.999)]\n",
      "[2023-04-20 07:36:20,923] [INFO] [timer.py:199:stop] epoch=0/micro_step=980/global_step=980, RunningAvgSamplesPerSec=5037.7391366754455, CurrSamplesPerSec=5321.032667300983, MemAllocated=0.0GB, MaxMemAllocated=1.87GB\n",
      "Epoch: 9, Loss: 1.95, acc: 0.51, time cost: 2.81s\n"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=8 main.py --use-deepspeed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 下一节中，我们重点关注DeepSpeed下所给出的一些API方法"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
