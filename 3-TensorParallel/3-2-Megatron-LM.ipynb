{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Megatron-LM张量并行\n",
    "\n",
    "Megatron是由 NVIDIA 的应用深度学习研究团队开发的大型、强大的Transformer模型，主要针对大规模训练大型 transformer 语言模型的研究。其主要贡献时提出了将模型进行横向分割而进行张量并行的思想。\n",
    "\n",
    "关于Tensor parallelism的中文解读可以参考：\n",
    "\n",
    "英伟达中国：https://zhuanlan.zhihu.com/p/420908718\n",
    "\n",
    "知乎大佬对具体切分方法的图示+伪代码：https://zhuanlan.zhihu.com/p/366906920\n",
    "\n",
    "博客园罗西的思考：https://www.cnblogs.com/rossiXYZ/p/15840803.html\n",
    "\n",
    "这一节Notebook主要想介绍针对一个比较简单的模型，如何使用Megatron快速将其进行张量并行的部署"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，安装megatron库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/Megatron-LM.git\n",
    "!cd Megatron-LM\n",
    "%pip install -v -e ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试安装是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'megatron' from '/mnt/configblob/users/ruizhe/Megatron-LM/megatron/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import megatron\n",
    "\n",
    "print(megatron)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单元测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来的代码部分引用了Megatron单元测试的代码：https://github.com/NVIDIA/Megatron-LM/tree/main/tests/unit_tests\n",
    "\n",
    "我们首先引入Megatron内做模型并行初始化的API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import megatron.core.parallel_state as ps\n",
    "from megatron.core.tensor_parallel.data import broadcast_data\n",
    "\n",
    "\n",
    "# 这个Utils类的作用是定义了初始化分布式环境，初始化模型并行环境，销毁模型并行环境的函数\n",
    "class Utils:\n",
    "\n",
    "    world_size = torch.cuda.device_count()\n",
    "    # 这个地方需要使用torchrun来启动分布式环境，否则这里的rank不会在环境变量中被发现，于是就直接报错了\n",
    "    rank = int(os.environ['LOCAL_RANK'])\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_distributed():\n",
    "        print(f'Initializing torch.distributed with rank: {Utils.rank}, world_size: {Utils.world_size}')\n",
    "        torch.cuda.set_device(Utils.rank % torch.cuda.device_count())\n",
    "        init_method = 'tcp://'\n",
    "        master_ip = os.getenv('MASTER_ADDR', 'localhost')\n",
    "        master_port = os.getenv('MASTER_PORT', '6000')\n",
    "        init_method += master_ip + ':' + master_port\n",
    "        torch.distributed.init_process_group(backend='nccl', world_size=Utils.world_size, rank=Utils.rank, init_method=init_method)\n",
    "        \n",
    "    @staticmethod\n",
    "    def destroy_model_parallel():\n",
    "        ps.destroy_model_parallel()\n",
    "        torch.distributed.barrier()\n",
    "\n",
    "    ''' initial_model_parallel: 初始化模型并行环境：\n",
    "    tensor_model_parallel_size: 指定张量并行级别\n",
    "    pipeline_model_parallel_size: 指定模型并行级别\n",
    "    virtual_pipeline_model_parallel_size: 指定虚拟模型并行级别\n",
    "    pipeline_model_parallel_split_rank: 指定模型并行切分的rank\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def initialize_model_parallel(tensor_model_parallel_size = 1, pipeline_model_parallel_size = 1, virtual_pipeline_model_parallel_size = None, pipeline_model_parallel_split_rank = None):\n",
    "        ps.destroy_model_parallel()\n",
    "        if not torch.distributed.is_initialized():\n",
    "            Utils.initialize_distributed()\n",
    "        ps.initialize_model_parallel(tensor_model_parallel_size, pipeline_model_parallel_size, virtual_pipeline_model_parallel_size, pipeline_model_parallel_split_rank)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们可以定义一些单元测试，比如这里的代码测试megatron的**张量广播**功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试广播：指定张量并行级别为2，模型并行级别为4的这样的一个分布式环境，然后制造一些数据，看看broadcast_data的效果\n",
    "def test_broadcast_data():\n",
    "    Utils.initialize_model_parallel(2,4)\n",
    "    input_data = {\n",
    "        0 : torch.ones((8,8)).cuda() * 0.0,\n",
    "        1 : torch.ones((8,8)).cuda() * 1.0,\n",
    "        2 : torch.ones((8,8)).cuda() * 2.0,\n",
    "        3 : torch.ones((8,8)).cuda() * 3.0,\n",
    "        4 : torch.ones((8,8)).cuda() * 4.0,\n",
    "        5 : torch.ones((8,8)).cuda() * 5.0,\n",
    "        6 : torch.ones((8,8)).cuda() * 6.0,\n",
    "        7 : torch.ones((8,8)).cuda() * 7.0\n",
    "        }\n",
    "    dtype = torch.float32\n",
    "    # broadcast_data：将rank=0的进程的数据广播到所有进程\n",
    "    actual_output = broadcast_data([0,1],input_data, dtype)\n",
    "    assert(torch.equal(actual_output[0], input_data[0]))\n",
    "    assert(torch.equal(actual_output[1], input_data[1]))\n",
    "    \n",
    "    if Utils.rank == 0:\n",
    "        print(\"Broadcast assertion passed\")\n",
    "    Utils.destroy_model_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Initializing torch.distributed with rank: 0, world_size: 8\n",
      "Initializing torch.distributed with rank: 2, world_size: 8\n",
      "Initializing torch.distributed with rank: 6, world_size: 8\n",
      "Initializing torch.distributed with rank: 5, world_size: 8\n",
      "Initializing torch.distributed with rank: 4, world_size: 8\n",
      "Initializing torch.distributed with rank: 1, world_size: 8\n",
      "Initializing torch.distributed with rank: 3, world_size: 8\n",
      "Initializing torch.distributed with rank: 7, world_size: 8\n",
      "Broadcast assertion passed\n"
     ]
    }
   ],
   "source": [
    "!TEST_BROAD=1 torchrun --nproc_per_node=8 test_megatron.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来进行张量并行级别，各并行张量间收集数据的测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试copy_to_model_parallel_region：此时张量并行级别为4，模型并行级别为2\n",
    "\n",
    "from megatron.core.tensor_parallel import mappings\n",
    "def test_CopyToModelParallelRegion():\n",
    "    Utils.initialize_model_parallel(4,2)\n",
    "    input_data = torch.ones((1)).cuda()*Utils.rank\n",
    "    output_data = mappings._CopyToModelParallelRegion.backward(None, input_data)\n",
    "    result = torch.ones(1).cuda()\n",
    "    \n",
    "    # 这里result的结果：因为张量并行级别为4，所以0，1，2，3这四张卡是彼此收集数据的，他们上面的tensor值分别为(0,1,2,3)，加起来后每个便都为6；在流水线并行级别的第二层，4，5，6，7这四张卡也是彼此收集数据的，他们上面的tensor值分别为(4,5,6,7)，加起来后每个便都为22\n",
    "    result = result * 22 if Utils.rank >= 4 else result * 6\n",
    "    assert(torch.equal(output_data, result))\n",
    "    print(f'rank: {Utils.rank}, input_data: {input_data}, output_data: {output_data}')\n",
    "    assert(torch.equal(input_data, mappings.copy_to_tensor_model_parallel_region(input_data)))\n",
    "    assert(torch.equal(input_data, mappings._CopyToModelParallelRegion.symbolic(None, input_data)))\n",
    "    \n",
    "    \n",
    "    print_in_rank_zero(\"Copy to model parallel region test passed\")\n",
    "    Utils.destroy_model_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Initializing torch.distributed with rank: 5, world_size: 8\n",
      "Initializing torch.distributed with rank: 2, world_size: 8\n",
      "Initializing torch.distributed with rank: 6, world_size: 8\n",
      "Initializing torch.distributed with rank: 0, world_size: 8\n",
      "Initializing torch.distributed with rank: 7, world_size: 8\n",
      "Initializing torch.distributed with rank: 1, world_size: 8\n",
      "Initializing torch.distributed with rank: 3, world_size: 8\n",
      "Initializing torch.distributed with rank: 4, world_size: 8\n",
      "rank: 2, input_data: tensor([6.], device='cuda:2'), output_data: tensor([6.], device='cuda:2')\n",
      "rank: 3, input_data: tensor([6.], device='cuda:3'), output_data: tensor([6.], device='cuda:3')\n",
      "rank: 1, input_data: tensor([6.], device='cuda:1'), output_data: tensor([6.], device='cuda:1')\n",
      "rank: 0, input_data: tensor([6.], device='cuda:0'), output_data: tensor([6.], device='cuda:0')\n",
      "Copy to model parallel region test passed\n",
      "rank: 7, input_data: tensor([22.], device='cuda:7'), output_data: tensor([22.], device='cuda:7')\n",
      "rank: 4, input_data: tensor([22.], device='cuda:4'), output_data: tensor([22.], device='cuda:4')\n",
      "rank: 6, input_data: tensor([22.], device='cuda:6'), output_data: tensor([22.], device='cuda:6')\n",
      "rank: 5, input_data: tensor([22.], device='cuda:5'), output_data: tensor([22.], device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "!TEST_COPY=1 torchrun --nproc_per_node=8 test_megatron.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分内容与`all_reduce`的操作很像，这里就不再赘述，将命令行开头令TEST_REDUCE=1即可看到测试`all_reduce`的结果"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来这部分是测试`all_gather_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import megatron.core.tensor_parallel.utils as util\n",
    "\n",
    "# 测试all_gather\n",
    "def test_gather_split_1d_tensor():\n",
    "    rank = Utils.rank\n",
    "    Utils.initialize_model_parallel(tensor_model_parallel_size=2, pipeline_model_parallel_size=4)\n",
    "    input_tensor = torch.ones((2,4)).cuda() * rank\n",
    "    actual_output_tensor = util.gather_split_1d_tensor(input_tensor)\n",
    "    if rank %2 == 0:\n",
    "        expected_output_tensor = torch.concat((input_tensor.flatten(), input_tensor.flatten() + 1))\n",
    "    else : \n",
    "        expected_output_tensor = torch.concat((input_tensor.flatten() - 1, input_tensor.flatten()))\n",
    "    assert(torch.equal(actual_output_tensor, expected_output_tensor))\n",
    "    Utils.destroy_model_parallel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:torch.distributed.run:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "Initializing torch.distributed with rank: 1, world_size: 8\n",
      "Initializing torch.distributed with rank: 7, world_size: 8\n",
      "Initializing torch.distributed with rank: 0, world_size: 8\n",
      "Initializing torch.distributed with rank: 4, world_size: 8\n",
      "Initializing torch.distributed with rank: 5, world_size: 8\n",
      "Initializing torch.distributed with rank: 2, world_size: 8\n",
      "Initializing torch.distributed with rank: 6, world_size: 8\n",
      "Initializing torch.distributed with rank: 3, world_size: 8\n",
      "rank: 1, input_tensor: tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], device='cuda:1'); output_tensor: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       device='cuda:1')\n",
      "rank: 7, input_tensor: tensor([[7., 7., 7., 7.],\n",
      "        [7., 7., 7., 7.]], device='cuda:7'); output_tensor: tensor([6., 6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 7., 7., 7., 7.],\n",
      "       device='cuda:7')\n",
      "rank: 6, input_tensor: tensor([[6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.]], device='cuda:6'); output_tensor: tensor([6., 6., 6., 6., 6., 6., 6., 6., 7., 7., 7., 7., 7., 7., 7., 7.],\n",
      "       device='cuda:6')\n",
      "rank: 2, input_tensor: tensor([[2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2.]], device='cuda:2'); output_tensor: tensor([2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
      "       device='cuda:2')\n",
      "rank: 0, input_tensor: tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0'); output_tensor: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       device='cuda:0')\n",
      "rank: 4, input_tensor: tensor([[4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4.]], device='cuda:4'); output_tensor: tensor([4., 4., 4., 4., 4., 4., 4., 4., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
      "       device='cuda:4')\n",
      "rank: 3, input_tensor: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]], device='cuda:3'); output_tensor: tensor([2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
      "       device='cuda:3')\n",
      "Gather split 1d tensor test passed\n",
      "rank: 5, input_tensor: tensor([[5., 5., 5., 5.],\n",
      "        [5., 5., 5., 5.]], device='cuda:5'); output_tensor: tensor([4., 4., 4., 4., 4., 4., 4., 4., 5., 5., 5., 5., 5., 5., 5., 5.],\n",
      "       device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "!TEST_GATHER_SPLIT=1 torchrun --nproc_per_node=8 test_megatron.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里从all_gather的结果看出，因为是设置了张量并行级别为2，流水线并行级别为4，因此同一批次的tensor从横向是被划分到两张卡上（张量并行），所以`test_gather_split_1d_tensor()`这个函数的all_gather收集是横向收集的，而不涉及后续的纵向流水线并行。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型部署\n",
    "\n",
    "将Megatron-LM张量并行系统直接部署到一个简单的Transformer模型上。这部分内容参考Megatron-LM官方的指导文档：https://docs.nvidia.com/megatron-core/developer-guide/latest/user-guide/index.html#quick-start\n",
    "\n",
    "由于Megatron-LM在张量并行中重新定义了FFN和Self-Attention的前向传播/反向传播过程，所以我们很难将一个现成的模型添加一些语句使其能够进行模型并行（先前提到的数据并行就不是这样，因为数据并行使用的是pytorch原生的API，因此像是已经写好的模型训练脚本可以通过简单的并行环境搭建和一些必要的改动使其能够数据并行）。此外，数据并行和megatron模型并行另一显著差异再于，megatron模型并行目前只为transformer架构的模型做了设计，不过这也符合目前主流神经网络研究的趋势。\n",
    "\n",
    "以下代码除了在Jupyter Notebook内展示外，还全部包括在./simple_megatron_transformer.py文件中，启动该文件的方式也依然是使用命令行中的torchrun去launch这样一个分布式训练的py文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化分布式环境。这里利用了2张GPU做初始化，其中张量并行化尺寸设为1，流水线并行化尺寸设为1\n",
    "import os\n",
    "import torch\n",
    "from megatron.core import parallel_state\n",
    "\n",
    "def initialize_distributed(tensor_model_parallel_size = 1, pipeline_model_parallel_size = 1):\n",
    "    # Torch setup for distributed training\n",
    "    rank = int(os.environ['LOCAL_RANK'])\n",
    "    world_size = torch.cuda.device_count()\n",
    "    torch.cuda.set_device(rank)\n",
    "    torch.distributed.init_process_group(world_size=world_size, rank=rank)\n",
    "\n",
    "    # Megatron core distributed training initialization\n",
    "    parallel_state.initialize_model_parallel(tensor_model_parallel_size, pipeline_model_parallel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用Megatron提供的API初始化一个很简单2层的Transformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.core.transformer.transformer_config import TransformerConfig\n",
    "from megatron.core.models.gpt.gpt_model import GPTModel\n",
    "from megatron.core.models.gpt.gpt_layer_specs import get_gpt_layer_local_spec\n",
    "\n",
    "def model_provider():\n",
    "    \"\"\"Build the model.\"\"\"\n",
    "\n",
    "    transformer_config = TransformerConfig(\n",
    "        num_layers=2,\n",
    "        hidden_size=12,\n",
    "        num_attention_heads=4,\n",
    "        use_cpu_initialization=True,\n",
    "        pipeline_dtype=torch.float32)\n",
    "\n",
    "    gpt_model = GPTModel(\n",
    "        config=transformer_config,\n",
    "        transformer_layer_spec=get_gpt_layer_local_spec(),\n",
    "        vocab_size=100,\n",
    "        max_sequence_length=64)\n",
    "\n",
    "    return gpt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成一个虚假的数据集用来训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from megatron.core.datasets.utils import Split\n",
    "from megatron.core.datasets.gpt_dataset import GPTDatasetConfig, MockGPTDataset\n",
    "\n",
    "def get_train_data_iterator():\n",
    "    config = GPTDatasetConfig(\n",
    "        is_built_on_rank=lambda:(parallel_state.is_pipeline_last_stage() or parallel_state.is_pipeline_first_stage()),\n",
    "        random_seed = 0,\n",
    "        sequence_length = 64,\n",
    "        blend=[],\n",
    "        mock=True,\n",
    "        reset_position_ids=False,\n",
    "        reset_attention_mask=False,\n",
    "        eod_mask_loss=False,\n",
    "        tokenizer=\"dummy\")\n",
    "\n",
    "    training_data= MockGPTDataset(Split.train, config)\n",
    "\n",
    "    train_dataloader = DataLoader(training_data, batch_size=8, shuffle=True)\n",
    "\n",
    "    train_iterator = iter(train_dataloader)\n",
    "    return train_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 接下来，定义前向函数。注意到这个前向函数是接受到了一个输入参数`data_iterator`，这个数据器是从dataloader中获取的。同时它的返回值是前向的输出和损失函数。这个函数输入输出的设计方式略为奇特，但megatron官方认为这样的设计更加高效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def forward_step_func(data_iterator, model):\n",
    "\n",
    "    def loss_func(loss_mask: torch.Tensor, output_tensor: torch.Tensor):\n",
    "\n",
    "        losses = output_tensor.float()\n",
    "        loss_mask = loss_mask.view(-1).float()\n",
    "        loss = torch.sum(losses.view(-1) * loss_mask) / loss_mask.sum()\n",
    "        # If you have data parallel reduce loss across data parallel groups.\n",
    "        # If pipeline parallel, loss computation is done only in last stage.\n",
    "\n",
    "        return loss, {'lm loss': loss}\n",
    "\n",
    "    data = next(data_iterator)\n",
    "    tokens = data['tokens'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    position_ids = data['position_ids'].to(device)\n",
    "    labels = data['labels'].to(device)\n",
    "    loss_mask = data['loss_mask'].to(device)\n",
    "\n",
    "    output_tensor = model(tokens, position_ids, attention_mask,\n",
    "                          labels=labels)\n",
    "\n",
    "    return output_tensor, partial(loss_func, loss_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 接下来是进行分布式保存和加载checkpoint的函数。megatron设计的这种保存和加载checkpoint的方式比较高效，使得用户可以灵活地调节checkpoint。比如，一个使用张量并行级别为2的模型，可以被读取成张量并行级别为4\n",
    "#### 注意：这部分代码可能需要安装额外的依赖：zarr和tensorstore:\n",
    "```sh\n",
    "pip install tensorstore==0.1.45\n",
    "pip install zarr\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from megatron.core import dist_checkpointing\n",
    "\n",
    "def save_distributed_checkpoint(checkpoint_path, gpt_model):\n",
    "    sharded_state_dict = gpt_model.sharded_state_dict(prefix='')\n",
    "    dist_checkpointing.save(sharded_state_dict=sharded_state_dict, checkpoint_dir=checkpoint_path)\n",
    "\n",
    "def load_distributed_checkpoint(checkpoint_path, gpt_model):\n",
    "    sharded_state_dict=gpt_model.sharded_state_dict(prefix='')\n",
    "    checkpoint = dist_checkpointing.load(sharded_state_dict=sharded_state_dict, checkpoint_dir=checkpoint_path)\n",
    "    gpt_model.load_state_dict(checkpoint)\n",
    "    return gpt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 接下来是训练主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.optim import Adam\n",
    "from megatron.core.pipeline_parallel.schedules import get_forward_backward_func\n",
    "from megatron.core.tensor_parallel.random import model_parallel_cuda_manual_seed\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    initialize_distributed(tensor_model_parallel_size=2, pipeline_model_parallel_size=1)\n",
    "    model_parallel_cuda_manual_seed(123)\n",
    "\n",
    "    gpt_model = model_provider()\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpt_model.to(device)\n",
    "\n",
    "    optim = Adam(gpt_model.parameters())\n",
    "\n",
    "    train_iterator = get_train_data_iterator()\n",
    "\n",
    "    forward_backward_func = get_forward_backward_func()\n",
    "\n",
    "    # Running the model for 5 iterations\n",
    "    for _ in range(5):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        losses_reduced = forward_backward_func(\n",
    "            forward_step_func=forward_step_func,\n",
    "            data_iterator=train_iterator,\n",
    "            model=gpt_model,\n",
    "            num_microbatches=1,\n",
    "            seq_length=64,\n",
    "            micro_batch_size=8,\n",
    "            decoder_seq_length=64,\n",
    "            forward_only=False)\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        print(f'Losses reduced :{losses_reduced}')\n",
    "\n",
    "    # Saving the model\n",
    "    save_distributed_checkpoint(gpt_model=gpt_model, checkpoint_path='/workspace/ckpt')\n",
    "\n",
    "    # Loading the model\n",
    "    gpt_model = load_distributed_checkpoint(gpt_model=gpt_model, checkpoint_path='/workspace/ckpt')\n",
    "    gpt_model.to(device)\n",
    "    print('Successfully loaded the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一切准备好之后，便可以launch分布式脚本，观察输出。注意launch脚本时的安装包依赖问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc-per-node=2 simple_megatron_transformer.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}